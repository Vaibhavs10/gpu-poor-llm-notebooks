# GPU Poor LLM Notebooks âš¡

A good old T4 is more potent than you think!

This repository is a collection of notebooks to run <15B param LLMs using Transformers and Accelerate in `bfloat16`/ `float16` on the mighty T4.

I'll update this with each new LLM release. Feel free to open an issue with feature requests.

LLMs covered so far:
1. Mathstral 7B
2. Gemma 2 9B
3. CodeGemma
4. RecurrentGemma
5. Mistral Nemo 12B
